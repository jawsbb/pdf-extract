#!/usr/bin/env python3
"""
Test des corrections apportÃ©es Ã  l'interface Streamlit.
"""

import streamlit as st
import pandas as pd
import tempfile
import os
from pathlib import Path
import json
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_streamlit_corrections():
    """Test des corrections de l'interface Streamlit."""
    logger.info("ğŸ§ª TEST: Corrections interface Streamlit")
    
    # Simuler des donnÃ©es de test
    test_data = [
        {
            'department': '75',
            'commune': '101',
            'prefixe': '000',
            'section': 'AB',
            'numero': '123',
            'nom': 'MARTIN',
            'prenom': 'Jean',
            'adresse': '123 Rue de la Paix',
            'id': '75101000AB123',
            'fichier_source': 'test.pdf'
        },
        {
            'department': '75',
            'commune': '101',
            'prefixe': '000',
            'section': 'AB',
            'numero': '124',
            'nom': 'DUPONT',
            'prenom': 'Marie',
            'adresse': '456 Avenue du GÃ©nÃ©ral',
            'id': '75101000AB124',
            'fichier_source': 'test.pdf'
        }
    ]
    
    print("âœ… DonnÃ©es de test crÃ©Ã©es")
    
    # Test 1: VÃ©rification de la cohÃ©rence des fichiers
    def test_file_consistency():
        current_files = ['test.pdf', 'test2.pdf']
        processed_files = ['test.pdf']
        
        if current_files != processed_files:
            print("âš ï¸ IncohÃ©rence dÃ©tectÃ©e entre fichiers actuels et traitÃ©s")
            return False
        return True
    
    # Test 2: VÃ©rification du hash des fichiers
    def test_file_hash():
        files_data = [
            {'name': 'test.pdf', 'content': b'PDF content 1'},
            {'name': 'test2.pdf', 'content': b'PDF content 2'}
        ]
        
        hash1 = hash(tuple(f['name'] + str(len(f['content'])) for f in files_data))
        hash2 = hash(tuple(f['name'] + str(len(f['content'])) for f in files_data))
        
        if hash1 == hash2:
            print("âœ… Hash des fichiers cohÃ©rent")
            return True
        else:
            print("âŒ Hash des fichiers incohÃ©rent")
            return False
    
    # Test 3: Nettoyage des rÃ©sultats
    def test_results_cleanup():
        # Simuler le nettoyage
        session_state = {
            'extraction_results': test_data,
            'processed_files': ['test.pdf'],
            'current_file_hash': 12345
        }
        
        # Nettoyer
        session_state['extraction_results'] = None
        session_state['processed_files'] = []
        session_state['current_file_hash'] = None
        
        if all(v is None or v == [] for v in session_state.values()):
            print("âœ… Nettoyage des rÃ©sultats rÃ©ussi")
            return True
        else:
            print("âŒ Nettoyage des rÃ©sultats Ã©chouÃ©")
            return False
    
    # Test 4: Validation du DataFrame
    def test_dataframe_creation():
        try:
            df = pd.DataFrame(test_data)
            
            # VÃ©rifier les colonnes essentielles
            required_columns = ['department', 'commune', 'nom', 'prenom', 'id']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                print(f"âŒ Colonnes manquantes: {missing_columns}")
                return False
            
            print("âœ… DataFrame crÃ©Ã© avec succÃ¨s")
            return True
            
        except Exception as e:
            print(f"âŒ Erreur crÃ©ation DataFrame: {e}")
            return False
    
    # Test 5: Export des donnÃ©es
    def test_data_export():
        try:
            df = pd.DataFrame(test_data)
            
            # Test export CSV
            csv_data = df.to_csv(index=False, sep=';', encoding='utf-8-sig')
            if csv_data and len(csv_data) > 100:
                print("âœ… Export CSV rÃ©ussi")
            else:
                print("âŒ Export CSV Ã©chouÃ©")
                return False
            
            # Test export Excel (simulation)
            excel_columns = {
                'department': 'DÃ©partement',
                'commune': 'Commune',
                'nom': 'Nom Propri',
                'prenom': 'PrÃ©nom Propri',
                'id': 'ID'
            }
            
            df_export = df.rename(columns=excel_columns)
            if len(df_export.columns) >= 5:
                print("âœ… Export Excel prÃ©parÃ© avec succÃ¨s")
            else:
                print("âŒ Export Excel Ã©chouÃ©")
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur export donnÃ©es: {e}")
            return False
    
    # ExÃ©cuter tous les tests
    tests = [
        ("CohÃ©rence fichiers", test_file_consistency),
        ("Hash fichiers", test_file_hash),
        ("Nettoyage rÃ©sultats", test_results_cleanup),
        ("CrÃ©ation DataFrame", test_dataframe_creation),
        ("Export donnÃ©es", test_data_export)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
            print(f"{'âœ…' if result else 'âŒ'} {test_name}: {'PASS' if result else 'FAIL'}")
        except Exception as e:
            results.append((test_name, False))
            print(f"âŒ {test_name}: ERREUR - {e}")
    
    # RÃ©sumÃ©
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\nğŸ“Š RÃ‰SUMÃ‰ DES TESTS STREAMLIT:")
    print(f"âœ… Tests rÃ©ussis: {passed}/{total}")
    print(f"âŒ Tests Ã©chouÃ©s: {total - passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ Tous les tests Streamlit sont passÃ©s avec succÃ¨s!")
        return True
    else:
        print("âš ï¸ Certains tests ont Ã©chouÃ©. VÃ©rifiez les corrections.")
        return False

if __name__ == "__main__":
    test_streamlit_corrections() 